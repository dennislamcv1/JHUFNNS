{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c454f9ef",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"JHU.jpeg\" width=\"200\" alt=\"Johns Hopkins University logo\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed82811f",
   "metadata": {},
   "source": [
    "# Hands On Lab: Implementing and Training a Simple RNN for Sine Wave Prediction \n",
    "Estimated time needed: **60** minutes\n",
    "\n",
    "### Lab Overview:\n",
    "\n",
    "This hands-on lab demonstrates how to implement a simple RNN using PyTorch to predict the next value in a sine wave sequence. The sine wave serves as a simplified example of time-series data, allowing us to focus on understanding the mechanics of RNNs.\n",
    "By the end of this lab, you will have a working RNN capable of learning and predicting a sine wave, as well as a deeper understanding of how RNNs process sequential data.\n",
    "\n",
    "### Lab Objective:\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Understand the architecture and functionality of Recurrent Neural Networks (RNNs).\n",
    "2. Learn how to generate a sine wave dataset and structure it for sequential learning.\n",
    "3. Implement a custom RNN cell using PyTorch.\n",
    "4. Train the RNN model to minimize prediction error on the sine wave data.\n",
    "5. Visualize the model's predictions and compare them to the actual sine wave, evaluating its performance.\n",
    "\n",
    "### Tools and Libraries Used:\n",
    "\n",
    "1. **PyTorch:** For model implementation, training, and evaluation.\n",
    "2. **NumPy:** For sine wave generation and numerical computations.\n",
    "3. **Matplotlib:** For visualizing the sine wave and the RNNâ€™s prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06555c",
   "metadata": {},
   "source": [
    "## Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e464d9",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Libraries\n",
    "\n",
    "> **Note**: Please be patient while the required packages are being installed. This may take some time due to the multiple dependencies, but it should complete shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ae294",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb6fa9",
   "metadata": {},
   "source": [
    "### Step 2: Dataset Preparation\n",
    "**Task**:Generate a sine wave dataset, split it into sequences, and prepare it for the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013dfe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "seq_length = 50\n",
    "num_samples = 1000\n",
    "x = np.linspace(0, 50, num_samples)\n",
    "sine_wave = np.sin(x)\n",
    "#create the sequence\n",
    "#train the target\n",
    "#write the code here!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47b3130",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here to view/hide the solution.</summary>\n",
    "    \n",
    "```python\n",
    "    \n",
    "def create_sequences(data, seq_length):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        targets.append(data[i + seq_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "sequences, targets = create_sequences(sine_wave, seq_length)\n",
    "train_size = int(len(sequences) * 0.8)\n",
    "train_seq, test_seq = sequences[:train_size], sequences[train_size:]\n",
    "train_targets, test_targets = targets[:train_size], targets[train_size:]\n",
    "\n",
    "train_seq = torch.tensor(train_seq, dtype=torch.float32)\n",
    "train_targets = torch.tensor(train_targets, dtype=torch.float32)\n",
    "test_seq = torch.tensor(test_seq, dtype=torch.float32)\n",
    "test_targets = torch.tensor(test_targets, dtype=torch.float32)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "```\n",
    "</details> \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe4e610",
   "metadata": {},
   "source": [
    "### Step 3: Implementing the RNN Model\n",
    "**Task**:Define a simple RNN model with one hidden layer and an output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4702b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(hidden_size, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "    # write the code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15062fbe",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here to view/hide the solution.</summary>\n",
    "    \n",
    "```python\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.tanh(self.i2h(combined))\n",
    "        output = self.i2o(hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca1ffae",
   "metadata": {},
   "source": [
    "### Step 4: Training the Model\n",
    "### Explanation\n",
    "The code trains a Simple RNN using PyTorch for sequence prediction tasks. It processes input sequences step-by-step, computes loss using MSELoss, and optimizes model parameters with the Adam optimizer. The training loop runs for 100 epochs, initializing the hidden state at each epoch, accumulating loss over the sequence, and performing backpropagation. Progress is logged every 10 epochs, showing the model's learning performance.\n",
    "\n",
    "**Task**:Train the RNN to minimize the error in predicting the sine wave sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747add18",
   "metadata": {},
   "source": [
    "> **Note**: This block of code involves training an RNN for multiple epochs, with a sequence of data being processed step by step within each epoch. As the model iterates over each time step in the sequence, the computational cost increases, leading to longer processing times, especially with a larger number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b5399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and model parameters\n",
    "# Initialize the RNN model, loss function, and optimizer\n",
    "# Logging every 10 epochs\n",
    "# write the code here!\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b18ca",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here to view/hide the solution.</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 20\n",
    "batch_size = train_seq.size(0)\n",
    "\n",
    "model = SimpleRNN(input_size, hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for t in range(seq_length):\n",
    "        input = train_seq[:, t:t+1]\n",
    "        target = train_targets[:, None]\n",
    "        output, hidden = model(input, hidden)\n",
    "        loss += criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8eb156",
   "metadata": {},
   "source": [
    "### Step 5: Training the Model\n",
    "**Task**:Use the trained model to make predictions and compare them with the true sine wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a24eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#write the code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0729da97",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here to view/hide the solution.</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "model.eval()\n",
    "test_hidden = model.init_hidden(test_seq.size(0))\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t in range(test_seq.size(1)):\n",
    "        input = test_seq[:, t:t+1]\n",
    "        output, test_hidden = model(input, test_hidden)\n",
    "        predictions.append(output.numpy())\n",
    "\n",
    "predictions = np.array(predictions).squeeze().T\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(sine_wave[len(train_seq):], label='True')\n",
    "plt.plot(predictions.flatten(), label='Predicted', linestyle='dashed')\n",
    "plt.legend()\n",
    "plt.title('Sine Wave Prediction with Simple RNN')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec002c",
   "metadata": {},
   "source": [
    "### Expected Output:\n",
    "\n",
    "1. **Training Results:** The loss should decrease as the model learns the sine wave pattern.\n",
    "2. **Visualization:** The predicted sine wave (dashed line) should closely match the true sine wave (solid line), indicating the model's success in generalizing the pattern.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "In this lab, you successfully:\n",
    "\n",
    "1. Built an RNN from scratch to handle sequential data.\n",
    "2. Trained the model on a sine wave dataset and evaluated its performance.\n",
    "3. Visualized the results to confirm the RNN's ability to predict sequential patterns.\n",
    "\n",
    "### Lab Summary:\n",
    "\n",
    "This lab explores the implementation and training of a simple Recurrent Neural Network (RNN) to predict the next value in a sine wave sequence. You will generate a sine wave dataset, preprocess it into sequential input-target pairs, and build an RNN using PyTorch. The RNN will be trained to minimize prediction error, leveraging its hidden states to capture temporal dependencies in the data. After training, the model's predictions will be evaluated and visualized against the actual sine wave to assess its performance. This lab provides foundational knowledge of RNNs and their application to time-series prediction tasks. Extensions include experimenting with LSTMs, GRUs, and hyperparameter tuning for improved results.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
