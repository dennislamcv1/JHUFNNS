{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ad4f82",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <img src=\"JHU.png\" width=\"200\" alt=\"Johns Hopkins University logo\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0415d39",
   "metadata": {},
   "source": [
    "# Hands-on Lab: Implementing a Basic Convolutional Neural Network (ConvNet)\n",
    "\n",
    "Estimated time needed: **60** minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5a77a",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "\n",
    "In this lab, you will learn how to implement a basic Convolutional Neural Network (ConvNet) using a deep learning framework like TensorFlow or PyTorch. The ConvNet will be trained on the MNIST dataset, a collection of grayscale images of handwritten digits (0â€“9). You will construct a network with at least two convolutional layers, pooling layers, and fully connected layers to classify these digits.\n",
    "\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "By the end of this lab, you will:\n",
    "\n",
    "- Understand the structure and functionality of convolutional and pooling layers.\n",
    "- Construct a ConvNet using a deep learning framework.\n",
    "- Train and evaluate the ConvNet on the MNIST dataset.\n",
    "- Visualize performance metrics such as accuracy and loss.\n",
    "- Extract insights about model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12076a2a",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "- **Dataset**: MNIST\n",
    "- **Features**: 28x28 grayscale images of handwritten digits.\n",
    "- **Classes**: 10 (digits 0 through 9).\n",
    "- **Size**: 60,000 training samples and 10,000 testing samples.\n",
    "- **Source**: Preloaded in popular deep learning frameworks like TensorFlow and PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cff208",
   "metadata": {},
   "source": [
    "## Assignment Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2010445b",
   "metadata": {},
   "source": [
    "### Step 1: Install and Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147b0e24",
   "metadata": {},
   "source": [
    "> **Note**: Please ignore any warnings that appear during execution; they will not affect the correctness of your code or the upcoming tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (if not already installed)\n",
    "!pip install tensorflow numpy matplotlib\n",
    "\n",
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd26fa1",
   "metadata": {},
   "source": [
    "### Task 2: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ad4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the images\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Reshape the data to include a channel dimension\n",
    "# Write your code here!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278c6c1",
   "metadata": {},
   "source": [
    "**Explanation**: \n",
    "\n",
    "- The MNIST dataset is loaded using Keras utilities.\n",
    "- Images are normalized to have pixel values between 0 and 1.\n",
    "- Reshaping adds a channel dimension to make the data compatible with the ConvNet input requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c55f0",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here to view/hide the solution.</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "# Reshape the data to include a channel dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "print(f\"Training data shape: {x_train.shape}, Testing data shape: {x_test.shape}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b416ce5",
   "metadata": {},
   "source": [
    "## Task 3: Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b354af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some sample images\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    \n",
    "    \n",
    "    # Write your code here!\n",
    "    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c529d",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "\n",
    "- Visualize 10 random images from the dataset to understand the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e062d3",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here to view/hide the solution.</summary>\n",
    "    \n",
    "```python\n",
    "    \n",
    "\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_train[i].squeeze(), cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bee64b",
   "metadata": {},
   "source": [
    "### Task 4: Define the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    # First convolutional layer\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Second convolutional layer\n",
    "\n",
    "    # Write your code here!\n",
    "    \n",
    "    \n",
    "    # Flattening the output and adding fully connected layers\n",
    "\n",
    "    # Write your code here!\n",
    "    \n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204ebf0",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "\n",
    "- Two convolutional layers are defined, each followed by a max-pooling layer.\n",
    "- Fully connected layers are added at the end to produce class probabilities.\n",
    "- `model.summary()` provides an overview of the network architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea1c75",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here to view/hide the solution.</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "    # Second convolutional layer\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Flattening the output and adding fully connected layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79496d4",
   "metadata": {},
   "source": [
    "### Task 5: Compile and Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db5e468",
   "metadata": {},
   "source": [
    "> **Note**:\n",
    "The code compiles and trains the model for 5 epochs, using the Adam optimizer and sparse categorical cross-entropy loss. Depending on the dataset size and available hardware, this process may take some time to complete, so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc903e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model for 5 epochs with training data (x_train, y_train) \n",
    "# and validate on test data (x_test, y_test); may take time depending on dataset size.\n",
    "\n",
    "# Write your code here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197c1ead",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "\n",
    "- The model is compiled with the Adam optimizer and categorical cross-entropy loss.\n",
    "- Training is performed for 5 epochs, with validation on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c3236",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here to view/hide the solution.</summary>\n",
    "    \n",
    "```python\n",
    "    \n",
    "# Train the model for 5 epochs with training data (x_train, y_train) \n",
    "# and validate on test data (x_test, y_test); may take time depending on dataset size.\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "    \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88eb79b",
   "metadata": {},
   "source": [
    "### Task 6: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance on the test data (x_test, y_test) and \n",
    "# print the test accuracy. The 'verbose=2' provides detailed output during evaluation.\n",
    "\n",
    "# Write your code here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458dd7d4",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here to view/hide the solution.</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "# Evaluate the model's performance on the test data (x_test, y_test) and \n",
    "# print the test accuracy. The 'verbose=2' provides detailed output during evaluation.\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"\\nTest accuracy: {test_acc}\")\n",
    "    \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcecb6ea",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "\n",
    "The model is evaluated on the test set to measure its performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f47759",
   "metadata": {},
   "source": [
    "### Task 7: Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss over epochs\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy\n",
    "# Write your code here!\n",
    "\n",
    "\n",
    "# Loss\n",
    "# Write your code here!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4f0cb",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here to view/hide the solution.</summary>\n",
    "    \n",
    "```python\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a59922c",
   "metadata": {},
   "source": [
    "**Explanation**:\n",
    "\n",
    "- Visualize the trends in training and validation accuracy and loss to understand the modelâ€™s learning progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73896c40",
   "metadata": {},
   "source": [
    "### Explaination of outcome:\n",
    "\n",
    "Achieving a **test accuracy more then 95%** on the MNIST dataset is excellent and entirely expected for a well-designed Convolutional Neural Network (ConvNet). Here's why:\n",
    "\n",
    "### **Why This Accuracy is Reasonable**\n",
    "1. **Dataset Characteristics**:  \n",
    "   The MNIST dataset is relatively simple, with well-structured and clean grayscale images of digits. Many models achieve over 99% accuracy on this dataset.\n",
    "\n",
    "2. **Model Design**:  \n",
    "   Your network includes:\n",
    "   - Two convolutional layers for feature extraction.\n",
    "   - Pooling layers to reduce spatial dimensions.\n",
    "   - Fully connected layers for final classification.  \n",
    "   This architecture is powerful enough to classify MNIST images with high accuracy.\n",
    "\n",
    "3. **Adam Optimizer**:  \n",
    "   The Adam optimizer adapts learning rates during training, which helps achieve convergence faster and more effectively.\n",
    "\n",
    "4. **Balanced Data**:  \n",
    "   The dataset is balanced across all 10 classes (digits 0â€“9), making it less prone to bias during training.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Next?**\n",
    "If you're curious about improving or testing the robustness of your model:\n",
    "- **Data Augmentation**: Apply transformations like rotations, scaling, or shifting to make the model more robust to variations.\n",
    "- **Experiment with Hyperparameters**: Test different optimizers, learning rates, or architectures to explore their impact on performance.\n",
    "- **Use a Complex Dataset**: Test your model on more challenging datasets like CIFAR-10 or Fashion-MNIST for broader insights.\n",
    "\n",
    "Your results confirm that your implementation is correct, and the model is performing as expected for this dataset. Great work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf1f01d",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "- ConvNets are powerful for image classification tasks due to their ability to extract spatial features.\n",
    "- Adding multiple convolutional and pooling layers improves feature extraction but increases computational cost.\n",
    "- Training performance can be visualized using accuracy and loss curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e5fec0",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "In this lab, you implemented a basic ConvNet using TensorFlow. You trained the model on the MNIST dataset, achieving reasonable accuracy in classifying handwritten digits. You also learned to evaluate and visualize model performance, gaining insights into the network's learning dynamics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
